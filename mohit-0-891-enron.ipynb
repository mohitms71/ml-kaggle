{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport pickle\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Converting pickle file into dictionary**","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"original = \"/kaggle/input/dataset/final_project_dataset.pkl\"\ndestination = \"word_data_unix.pkl\"\n\ncontent = ''\noutsize = 0\nwith open(original, 'rb') as infile:\n    content = infile.read()\nwith open(destination, 'wb') as output:\n    for line in content.splitlines():\n        outsize += len(line) + 1\n        output.write(line + str.encode('\\n'))\n\ninfile = open('/kaggle/input/dataset/final_project_dataset_unix.pkl','rb')\nnew_dict = pickle.load(infile)\ninfile.close()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Creating Dataframe from dictionary**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.DataFrame.from_dict(new_dict)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Replacing NaN values with 0**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.replace('NaN', np.nan)\ndf=df.fillna(value=\"0\")\ndf2=df.T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Typecasting columns to integer and dropping columns that have large number of null entries**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df2[['salary','to_messages','deferral_payments','total_payments','loan_advances','bonus','deferred_income','total_stock_value',\n    'expenses','from_messages','long_term_incentive','director_fees','exercised_stock_options','other','restricted_stock','from_this_person_to_poi']]=df2[['salary','to_messages','deferral_payments','total_payments','loan_advances','bonus','deferred_income','total_stock_value',\n    'expenses','from_messages','long_term_incentive','director_fees','exercised_stock_options','other','restricted_stock','from_this_person_to_poi']].astype(int)\n\ndf2[['from_poi_to_this_person','restricted_stock_deferred','shared_receipt_with_poi']]=df2[['from_poi_to_this_person','restricted_stock_deferred','shared_receipt_with_poi']].astype(int)\ndf2=df2.drop(['email_address','loan_advances','restricted_stock_deferred','director_fees','deferral_payments'], axis = 1)\ndf2=df2.replace(\"False\",\"0\").replace(\"True\",\"1\")\ndf2['poi']=df2['poi'].astype(int)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Creating training and testing features**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfeatures=list(df2.columns)\ny=df2['poi']\ndf3=df2\ndf2=df2.drop(['poi'],axis=1)\nX=df2[df2.columns]\nX_train,X_test,y_train,y_test=train_test_split(X,y,random_state=0)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Preprocessing training and testing features**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler,MinMaxScaler,PowerTransformer,RobustScaler\nscaler=PowerTransformer(method='yeo-johnson').fit(X_train)\nX_train=scaler.transform(X_train)\nX_test=scaler.transform(X_test)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Performing cross validation for model selection**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\n\nmodel=KNeighborsClassifier()\nmodel1=GradientBoostingClassifier()\n\nmodel3=RandomForestClassifier()\nmodel4=LogisticRegression(solver='liblinear')\nmodel5=SVC()\nmodel6=DecisionTreeClassifier()\nb=[]\nfor i in range(5,11):\n    acc=cross_val_score(model,X,y,cv=i)\n    acc1=cross_val_score(model1,X,y,cv=i)\n    \n    acc3=cross_val_score(model3,X,y,cv=i)\n    acc4=cross_val_score(model4,X,y,cv=i)\n    acc5=cross_val_score(model5,X,y,cv=i)\n    acc6=cross_val_score(model6,X,y,cv=i)\n    b.extend([acc.mean(),acc1.mean(),acc3.mean(),acc4.mean(),acc5.mean(),acc6.mean()])\nb=np.asarray(b).reshape(-1,6)\nprint(\"Best cross validation score:- \"+str(np.amax(b)))\na1= np.where(b==np.amax(b))[1]\na2= np.where(b==np.amax(b))[0]\nif a1==[0]:\n    print(\"K nearest neighbors\")\nelif a1==[1]:\n    print(\"Gradient Boosting Classifier\")\n\nelif a1==[2]:\n    print(\"Random Forest Classifier\")\nelif a1==[3]:\n    print(\"Logistic Regression\")\nelif a1==[4]:\n    print(\"Support Vector Classifier\")\nelse:\n    print(\"Decision Tree Classifier\")\nif a2==[0]:\n    print(\"No. of folds:- 5\")\nelif a2==[1]:\n    print(\"No. of folds:- 6\")\nelif a2==[2]:\n    print(\"No. of folds:- 7\")\nelif a2==[3]:\n    print(\"No. of folds:- 8\")\nelif a2==[4]:\n    print(\"No. of folds:- 9\")\nelif a2==[5]:\n    print(\"No. of folds:- 10\")\nelse:\n    print(\"No. of folds:- 11\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Performing Grid Search for hyperparameter tuning**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\ngrid_values={'n_neighbors':list(range(1,70)),\n              }\ngrid_model=GridSearchCV(model,param_grid=grid_values,scoring='accuracy',cv=8).fit(X_train,y_train)\nprint(\"Best paramters:- \"+str(grid_model.best_params_))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Fitting tuned model and predicting probabilities of each class**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model=KNeighborsClassifier(n_neighbors=grid_model.best_estimator_.get_params()['n_neighbors'])\nmodel.fit(X_train,y_train)\ny_pred=model.predict_proba(X_test)\nprint(model.predict(X_test))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Model evaluation using different metrics**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score,roc_curve,classification_report\nprint(\"Accuracy training set:- \"+str(model.score(X_train,y_train)))\nprint(\"Accuracy testing set:- \"+str(model.score(X_test,y_test)))\nprint(\"ROC Score:- \"+str(roc_auc_score(y_test,y_pred[:,1])))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Converting data into pickle file**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pickle.dump(model,open(\"my_classifier.pkl\",\"wb\"))\npickle.dump(new_dict,open(\"my_dataset.pkl\",\"wb\"))\npickle.dump(features,open(\"my_feature_list\",\"wb\"))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}